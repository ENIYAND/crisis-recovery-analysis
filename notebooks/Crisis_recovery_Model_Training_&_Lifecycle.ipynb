{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93dcbb56-5e42-478e-9cd7-ae4d1e41ec3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Crisis_recovery_Model_Training_and_Lifecycle\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook manages the **machine learning lifecycle**\n",
    "for the **Crisis Recovery Lakehouse**.\n",
    "\n",
    "It is responsible for:\n",
    "- Training churn and risk prediction models\n",
    "- Validating model performance\n",
    "- Registering models into MLflow\n",
    "- Managing model versions and stages (Staging → Production)\n",
    "\n",
    "This notebook converts **analytical features**\n",
    "into **predictive intelligence** used for proactive crisis response.\n",
    "\n",
    "---\n",
    "\n",
    "## Business Context\n",
    "\n",
    "During a crisis, **reactive dashboards are not enough**.\n",
    "\n",
    "Leadership and operations teams need:\n",
    "- Early warnings about customer churn\n",
    "- Signals of worsening customer experience\n",
    "- Prioritization of intervention before losses occur\n",
    "\n",
    "Machine learning enables the organization to:\n",
    "- Predict customer risk instead of reacting late\n",
    "- Target recovery actions efficiently\n",
    "- Measure crisis impact quantitatively\n",
    "\n",
    "This notebook operationalizes that intelligence.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs and Outputs\n",
    "\n",
    "### Inputs (from Gold / Feature Engineering Layer)\n",
    "\n",
    "| Source Table | Purpose |\n",
    "|-------------|--------|\n",
    "| `ml_churn_features` | Model-ready customer features |\n",
    "| `gold_customer_churn_risk` (optional baseline) | Benchmark comparison |\n",
    "\n",
    "All features are:\n",
    "- Cleaned\n",
    "- Aggregated\n",
    "- Free of raw text\n",
    "- Safe for ML consumption\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs\n",
    "\n",
    "| Artifact | Business Purpose |\n",
    "|--------|------------------|\n",
    "| Trained ML model | Predict customer churn risk |\n",
    "| MLflow experiment | Track model runs & metrics |\n",
    "| Registered model | Enable deployment & governance |\n",
    "| Model version history | Auditability & rollback |\n",
    "\n",
    "---\n",
    "\n",
    "## ML Design Principles\n",
    "\n",
    "- Models must be **interpretable**\n",
    "- Features must be **business-explainable**\n",
    "- Performance must be **measured on unseen data**\n",
    "- Every model must be **tracked and versioned**\n",
    "- No model training occurs on raw or Silver data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0263b4f-8599-424e-9299-fea3ebf255f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "CREATE VOLUME IF NOT EXISTS workspace.food_delivery.mlflow_models_temp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3371a80-a70f-4161-b205-4d953aa97c05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Feature Definition\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "To predict customer churn during a crisis, the model must rely on\n",
    "**behavioral, experiential, and engagement signals** rather than raw events.\n",
    "\n",
    "Poor or irrelevant features lead to:\n",
    "- Unstable models\n",
    "- False churn predictions\n",
    "- Low trust from business teams\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We explicitly define a **curated feature set** that captures:\n",
    "- Customer activity (`total_orders`)\n",
    "- Experience quality (`avg_star_rating`, `late_order_ratio`)\n",
    "- Crisis sensitivity (`crisis_exposure_index`, `sentiment_velocity`)\n",
    "- Value & engagement (`rfm_score`, `segment_index`)\n",
    "\n",
    "These features are already:\n",
    "- Aggregated\n",
    "- Normalized upstream\n",
    "- Approved for ML usage\n",
    "\n",
    "## 2. Load Training Dataset\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Machine learning models must be trained on\n",
    "**clean, stable, and business-aligned data**.\n",
    "\n",
    "Training directly from Silver or raw tables would:\n",
    "- Mix analytical and ML concerns\n",
    "- Increase leakage risk\n",
    "- Reduce reproducibility\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We load data from the **ML feature layer** (`ml_churn_features`),\n",
    "which represents the **single source of truth for model training**.\n",
    "\n",
    "This table is:\n",
    "- Feature-engineered upstream\n",
    "- Validated for nulls and ranges\n",
    "- Safe for repeated model experiments\n",
    "\n",
    "\n",
    "## 3. Train–Test Split\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "A model that performs well only on historical data\n",
    "cannot be trusted in production.\n",
    "\n",
    "Without a proper split:\n",
    "- Metrics become misleading\n",
    "- Overfitting goes undetected\n",
    "- Real churn risk is underestimated\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We split the dataset into:\n",
    "- **80% training data** → model learning\n",
    "- **20% test data** → unbiased evaluation\n",
    "\n",
    "A fixed seed ensures:\n",
    "- Reproducibility\n",
    "- Comparable experiment runs\n",
    "\n",
    "## 4. Feature Vector Assembly\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Spark ML algorithms require features to be represented\n",
    "as a **single vector column**.\n",
    "\n",
    "Passing raw columns directly to the model\n",
    "is not supported and breaks pipeline execution.\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We use `VectorAssembler` to:\n",
    "- Combine all selected feature columns\n",
    "- Produce a unified `features` vector\n",
    "\n",
    "This step is **technical, not analytical** —\n",
    "no feature transformation logic happens here.\n",
    "\n",
    "## 5. Model Definition\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Churn behavior during crises is:\n",
    "- Non-linear\n",
    "- Influenced by multiple interacting factors\n",
    "- Sensitive to recent negative experiences\n",
    "\n",
    "A simple linear model may fail to capture these patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We use a **Gradient-Boosted Trees (GBT) classifier** because it:\n",
    "- Handles non-linear relationships well\n",
    "- Is robust to feature interactions\n",
    "- Performs reliably on tabular behavioral data\n",
    "\n",
    "Tree depth is limited to control overfitting.\n",
    "\n",
    "## 6. ML Pipeline Construction\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Manually managing multiple ML steps increases:\n",
    "- Operational complexity\n",
    "- Risk of inconsistent transformations\n",
    "- Deployment errors\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We build a Spark ML **Pipeline** that:\n",
    "- Assembles features\n",
    "- Trains the classifier\n",
    "- Applies transformations consistently\n",
    "\n",
    "This ensures the **same logic** is used during:\n",
    "- Training\n",
    "- Evaluation\n",
    "- Future inference\n",
    "\n",
    "## 7. MLflow Artifact Storage Configuration\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Distributed Spark models require a\n",
    "**shared and accessible storage location**\n",
    "for logging artifacts.\n",
    "\n",
    "Incorrect paths cause:\n",
    "- Logging failures\n",
    "- Incomplete model registration\n",
    "- Broken lineage\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We define a Unity Catalog–compatible\n",
    "temporary storage path used by MLflow\n",
    "to stage model artifacts before upload.\n",
    "\n",
    "\n",
    "## 8. MLflow Experiment Setup\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Without structured experiment tracking:\n",
    "- Model results cannot be compared\n",
    "- Improvements cannot be justified\n",
    "- Governance audits become difficult\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We explicitly set the MLflow experiment so that:\n",
    "- All runs are grouped logically\n",
    "- Metrics are comparable across versions\n",
    "- Model history remains auditable\n",
    "\n",
    "## 9. Model Training Run\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Each training attempt must be:\n",
    "- Traceable\n",
    "- Reproducible\n",
    "- Measurable\n",
    "\n",
    "Ad-hoc model fitting without tracking\n",
    "breaks the ML lifecycle.\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We start an MLflow run to:\n",
    "- Train the pipeline\n",
    "- Generate predictions on unseen data\n",
    "- Capture metrics and parameters\n",
    "\n",
    "This run represents **one model version candidate**.\n",
    "\n",
    "## 10. Model Evaluation (Recall Focus)\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "In churn prediction, **missing a churner**\n",
    "is more costly than incorrectly flagging a loyal customer.\n",
    "\n",
    "Therefore, recall on churned users is critical.\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We evaluate the model using:\n",
    "- **Recall for label = 1 (churn)**\n",
    "\n",
    "This directly measures the model’s ability to:\n",
    "- Detect at-risk customers\n",
    "- Support proactive retention actions\n",
    "\n",
    "\n",
    "## 11. MLflow Logging\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Model metrics without context\n",
    "cannot be trusted or reused.\n",
    "\n",
    "We need to know:\n",
    "- How the model performed\n",
    "- Which features were used\n",
    "- Under which configuration it was trained\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "We log:\n",
    "- Recall metric for churn detection\n",
    "- Feature set description as a parameter\n",
    "\n",
    "This metadata enables:\n",
    "- Model comparison\n",
    "- Governance review\n",
    "- Informed promotion decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0274e3-6415-4f78-9f04-14e13b758c17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "# 1. Define Features\n",
    "feature_cols = [\n",
    "    \"total_orders\",\n",
    "    \"avg_star_rating\",\n",
    "    \"late_order_ratio\",\n",
    "    \"segment_index\",\n",
    "    \"crisis_exposure_index\",\n",
    "    \"sentiment_velocity\",\n",
    "    \"rfm_score\"\n",
    "]\n",
    "\n",
    "# 2. Load Data\n",
    "df = spark.table(\"food_delivery.ml_churn_features\")\n",
    "\n",
    "# 3. Train/Test Split\n",
    "# Splitting data: 80% for training, 20% for testing. \n",
    "# seed=42 ensures reproducibility\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 4. Feature Engineering\n",
    "# The VectorAssembler takes the list of columns and combines them into \n",
    "# a single vector column named \"features\", which Spark ML models require.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# 5. Define Model\n",
    "# Using Spark's native Gradient-Boosted Trees (GBT) classifier.\n",
    "# maxDepth=5 limits the depth of each tree to prevent overfitting.\n",
    "gbt = GBTClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    maxDepth=5\n",
    ")\n",
    "\n",
    "# 6. Build Pipeline\n",
    "# Chains the assembler and the model together. \n",
    "# When we call fit(), data flows through assembler -> gbt.\n",
    "pipeline = Pipeline(stages=[assembler, gbt])\n",
    "\n",
    "# 7. Define MLflow Storage Path\n",
    "# This path is required for distributed logging to Unity Catalog Volumes.\n",
    "uc_model_temp_path = \"/Volumes/workspace/food_delivery/mlflow_models_temp\"\n",
    "\n",
    "# 8. Set Experiment\n",
    "# Sets the context so all runs are grouped under this experiment name.\n",
    "mlflow.set_experiment(\"/Shared/QuickBite_Churn_Prediction\")\n",
    "\n",
    "# 9. Start Training Run\n",
    "with mlflow.start_run(run_name=\"GBT_Crisis_Aware_Pipeline\"):\n",
    "\n",
    "    # Train the pipeline on the training data\n",
    "    pipeline_model = pipeline.fit(train_df)\n",
    "    \n",
    "    # Generate predictions on the test data (automatically transforms features)\n",
    "    predictions = pipeline_model.transform(test_df)\n",
    "\n",
    "    # 10. Evaluation\n",
    "    # We use MulticlassEvaluator to calculate Recall specifically for label 1.\n",
    "    # churn=1 is the \"positive\" class we care about detecting.\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        metricName=\"recallByLabel\"\n",
    "    )\n",
    "\n",
    "    # The metricLabel parameter ensures we get recall for '1' (Churn), \n",
    "    # not the weighted average or the recall for '0'.\n",
    "    recall = evaluator.evaluate(\n",
    "        predictions,\n",
    "        {evaluator.metricLabel: 1}\n",
    "    )\n",
    "\n",
    "    # 11. Logging\n",
    "    # Log the numeric metric\n",
    "    mlflow.log_metric(\"recall_churn\", recall)\n",
    "    \n",
    "    # Log a parameter to describe the features used in this run\n",
    "    mlflow.log_param(\"feature_set\", \"baseline + crisis + rfm\")\n",
    "    \n",
    "    # Log the trained pipeline model. \n",
    "    # dfs_tmpdir is used to stage the model artifact before upload.\n",
    "    mlflow.spark.log_model(\n",
    "        pipeline_model, \n",
    "        \"churn_pipeline_model\",\n",
    "        dfs_tmpdir=uc_model_temp_path\n",
    "    )\n",
    "\n",
    "    # print(f\"Recall (churn=1): {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93a16bc3-80dd-4c18-9eb0-9db912d6e486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Signature & Production Logging\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "A trained model is not production-ready unless downstream systems know:\n",
    "- What inputs the model expects\n",
    "- What outputs it produces\n",
    "- How to validate requests at inference time\n",
    "\n",
    "Without a model signature:\n",
    "- Inference pipelines break silently\n",
    "- Feature mismatches cause runtime errors\n",
    "- Governance and review processes fail\n",
    "\n",
    "### Production Logging\n",
    "\n",
    "The trained Spark ML pipeline is logged to MLflow with:\n",
    "- Model artifact (`churn_pipeline_model`)\n",
    "- Inferred signature\n",
    "- Input example for testing and documentation\n",
    "\n",
    "Artifacts are staged through a Unity Catalog–compatible\n",
    "temporary volume to support distributed logging.\n",
    "\n",
    "This step finalizes the model as a **deployable, governed asset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "764c88a1-cce8-4239-b33e-e3139c9c1963",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select a small sample of feature columns from the training data for input example\n",
    "sample_input = train_df.select(feature_cols).limit(5)\n",
    "\n",
    "# Generate model predictions on the sample input to obtain output example\n",
    "sample_output = pipeline_model.transform(sample_input).select(\"prediction\")\n",
    "\n",
    "# Import MLflow's signature inference utility\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Define the temporary storage path for MLflow model artifacts\n",
    "uc_model_temp_path = \"/Volumes/workspace/food_delivery/mlflow_models_temp\"\n",
    "\n",
    "# Infer the model signature using the sample input and output\n",
    "signature = infer_signature(\n",
    "    sample_input.toPandas(),\n",
    "    sample_output.toPandas()\n",
    ")\n",
    "\n",
    "# Log the trained Spark ML pipeline model to MLflow with signature and input example\n",
    "mlflow.spark.log_model(\n",
    "    spark_model=pipeline_model,\n",
    "    artifact_path=\"churn_pipeline_model\",\n",
    "    dfs_tmpdir=uc_model_temp_path,\n",
    "    signature=signature,\n",
    "    input_example=sample_input.toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66e3e101-5063-4268-bd30-430a6143e141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model.transform(test_df).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6a288a7-4b8e-4839-a82e-1b8057138558",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> - Due to extreme class imbalance (≈0.12% churn rate) under a business-realistic churn definition (30+ days of inactivity), supervised churn prediction was not feasible without artificial resampling or proxy label redesign. This analysis instead highlights strong customer retention and underscores the critical role of churn definition in determining the viability of predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09c8a3ba-ceb7-4b00-a0d1-2fbcd0e110af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "This notebook establishes a **production-grade machine learning lifecycle**\n",
    "for crisis-aware churn prediction by:\n",
    "\n",
    "- Training a supervised churn model on curated, business-aligned features\n",
    "- Capturing non-linear customer behavior using Gradient-Boosted Trees\n",
    "- Evaluating performance with **recall-first metrics** aligned to churn risk\n",
    "- Tracking experiments, metrics, and parameters using MLflow\n",
    "- Registering a fully governed Spark ML pipeline with a formal model signature\n",
    "\n",
    "It acts as the **decision intelligence layer** of the Crisis Recovery Lakehouse,\n",
    "transforming engineered features into **predictive, auditable outcomes**.\n",
    "\n",
    "This ensures that churn models do not merely predict risk,\n",
    "but do so in a way that is:\n",
    "- Reproducible\n",
    "- Interpretable\n",
    "- Safe to deploy in production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9e70c8c-b9b9-4363-a3ab-5f8d90160b96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Downstream Dependencies\n",
    "\n",
    "The Model Training & Lifecycle layer feeds the following systems:\n",
    "\n",
    "### Churn Prediction & Scoring Jobs\n",
    "- Batch churn scoring pipelines\n",
    "- Daily / weekly customer risk refresh\n",
    "- Crisis-period churn monitoring\n",
    "\n",
    "---\n",
    "\n",
    "### MLflow Model Registry\n",
    "- Model versioning (v1, v2, …)\n",
    "- Stage transitions (Staging → Production)\n",
    "- Rollback and audit support\n",
    "- Governance and compliance workflows\n",
    "\n",
    "---\n",
    "\n",
    "### Business & Decision Systems\n",
    "- Retention and CRM targeting\n",
    "- Incentive and offer allocation\n",
    "- Crisis recovery prioritization\n",
    "- Executive churn risk reporting\n",
    "\n",
    "---\n",
    "\n",
    "Any failure or misalignment in this notebook directly impacts:\n",
    "- Model accuracy\n",
    "- Prediction reliability\n",
    "- Business decision quality\n",
    "\n",
    "This is why model training, evaluation, and registration\n",
    "must remain **precise, explainable, and reproducible**.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8806760165316922,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Crisis_recovery_Model_Training_&_Lifecycle",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
